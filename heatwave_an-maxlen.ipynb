{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4ff7a9-222d-4d32-b1be-1fb093ed2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac9bf4-9c43-4cfe-aff7-9475063cd305",
   "metadata": {},
   "source": [
    "# heatwave_an-maxlen.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cca7a29-42aa-483f-a1c1-0249b536a6a2",
   "metadata": {},
   "source": [
    "'''\n",
    "    File name: conditions_WBGT_monthmax.ipynb\n",
    "    Author: Andreas Prein\n",
    "    E-mail: prein@ucar.edu\n",
    "    Date created: 04.30.2024\n",
    "    Date last modified: 04.30.2024\n",
    "\n",
    "    ############################################################## \n",
    "    Needs data from:\n",
    "    \n",
    "    \n",
    "    Purpose:\n",
    "\n",
    "    1) Read in WBGT data year by year\n",
    "    2) calculates annual heatwave frequency and maximum length and stores data for future processing\n",
    "    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9533d4-aaa1-4f57-985b-5c201a143db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import rrule\n",
    "import datetime\n",
    "import glob\n",
    "from netCDF4 import Dataset\n",
    "import sys, traceback\n",
    "import dateutil.parser as dparser\n",
    "import string\n",
    "from pdb import set_trace as stop\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os\n",
    "# import pickle\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib as mpl\n",
    "import pylab as plt\n",
    "import random\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy\n",
    "import shapefile\n",
    "import matplotlib.path as mplPath\n",
    "from matplotlib.patches import Polygon as Polygon2\n",
    "# Cluster specific modules\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.cluster.vq import kmeans2,vq, whiten\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import seaborn as sns\n",
    "# import metpy.calc as mpcalc\n",
    "import shapefile as shp\n",
    "import sys\n",
    "from scipy.signal import wiener, filtfilt, butter, gaussian, freqz\n",
    "from scipy.ndimage import filters\n",
    "import pickle\n",
    "import time\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "import matplotlib.gridspec as gridspec\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c049f5ec-4983-40fa-b2f3-327a0fdd48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solar_time_difference_from_utc(longitude):\n",
    "    from datetime import datetime, timedelta, timezone\n",
    "    \"\"\"\n",
    "    Calculate the difference between local solar time and UTC based on the given longitude.\n",
    "\n",
    "    Args:\n",
    "    - longitude (float): The longitude of the location in degrees (East is positive, West is negative).\n",
    "\n",
    "    Returns:\n",
    "    - time_difference (timedelta): The difference from UTC as a timedelta object.\n",
    "    \"\"\"\n",
    "    # Calculate the time difference due to longitude (in minutes)\n",
    "    time_difference_minutes = longitude * 4  # 4 minutes per degree\n",
    "\n",
    "    # Create a timedelta object for the time difference\n",
    "    time_difference = timedelta(minutes=time_difference_minutes)\n",
    "    \n",
    "    return time_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a111ac-4ed1-49f2-9d33-74d99f02ff03",
   "metadata": {},
   "source": [
    "### User imput section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89c6039-8264-4938-8d8d-9fdd96bae37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/glade/campaign/mmm/c3we/prein/CONUS404/data/MonthlyData/GWBT/'\n",
    "save_dir_base = '/glade/campaign/mmm/c3we/prein/Papers/2024/2024_WBGT-climate-change/heatwaves/'\n",
    "\n",
    "simulation = \"pgw\" # \"ctr\" / \"pgw\"\n",
    "\n",
    "time_c404_ctr = pd.date_range(datetime.datetime(1980, 1, 1, 0), \n",
    "                              end=datetime.datetime(2021, 12, 31, 23), freq='h')\n",
    "years_ctr = np.unique(time_c404_ctr.year)\n",
    "conus404_pgw_dir = '/glade/campaign/mmm/c3we/prein/CONUS404/data/MonthlyData_PGW/GWBT/'\n",
    "time_c404_pgw = pd.date_range(datetime.datetime(1980, 1, 1, 0), \n",
    "                              end=datetime.datetime(2021, 12, 31, 23), freq='h')\n",
    "years_pgw = np.unique(time_c404_pgw.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eca03466-88ed-424e-a109-0b291bd2f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_channge = np.arange(0,3.1,0.1)\n",
    "delta_t = 0.25\n",
    "minyears = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f047f156-a309-481e-836d-8fa91afedccf",
   "metadata": {},
   "source": [
    "### Load global average LENS2 temperature for warming level selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b0b364-b268-46ab-abfe-9e2c5e1f8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/glade/u/home/prein/papers/2024/2024_WBGT_Climate-Change/data/NASA_global-av_t2m/graph.txt', delimiter=r\"\\s+\", header=0, skiprows=[0,1,2,4])\n",
    "\n",
    "StartDay = datetime.datetime(1850, 1, 15,1)\n",
    "StopDay = datetime.datetime(2101, 1, 15,0)\n",
    "Time=pd.date_range(StartDay, end=StopDay, freq='M')\n",
    "Time_years=pd.date_range(StartDay, end=StopDay, freq='Y')\n",
    "years = np.unique(Time.year)\n",
    "\n",
    "reference_period = [1950, 1980]\n",
    "\n",
    "lens2_t2m_dir = '/glade/campaign/mmm/c3we/mingge/DOD/LENS2/'\n",
    "ncid=Dataset(lens2_t2m_dir + 'TREFMNAV_monthly_globalAvg_185001-197912.nc', mode='r')\n",
    "TREFMNAV_hist = np.array(np.squeeze(ncid.variables['TREFMNAV'][:]))\n",
    "ncid.close()\n",
    "ncid=Dataset(lens2_t2m_dir + 'TREFMNAV_monthly_globalAvg_198001-201412.nc', mode='r')\n",
    "TREFMNAV_cur = np.array(np.squeeze(ncid.variables['TREFMNAV'][:]))\n",
    "ncid.close()\n",
    "ncid=Dataset(lens2_t2m_dir + 'TREFMNAV_monthly_globalAvg_201501-210012.nc', mode='r')\n",
    "TREFMNAV_fut = np.array(np.squeeze(ncid.variables['TREFMNAV'][:]))\n",
    "ncid.close()\n",
    "\n",
    "ncid=Dataset(lens2_t2m_dir + 'TREFMXAV_monthly_globalAvg_185001-197912.nc', mode='r')\n",
    "TREFMXAV_hist = np.array(np.squeeze(ncid.variables['TREFMXAV'][:]))\n",
    "ncid.close()\n",
    "ncid=Dataset(lens2_t2m_dir + 'TREFMXAV_monthly_globalAvg_198001-201412.nc', mode='r')\n",
    "TREFMXAV_cur = np.array(np.squeeze(ncid.variables['TREFMXAV'][:]))\n",
    "ncid.close()\n",
    "ncid=Dataset(lens2_t2m_dir + 'TREFMXAV_monthly_globalAvg_201501-210012.nc', mode='r')\n",
    "TREFMXAV_fut = np.array(np.squeeze(ncid.variables['TREFMXAV'][:]))\n",
    "ncid.close()\n",
    "\n",
    "TREFMNAV = np.append(TREFMNAV_hist, TREFMNAV_cur, axis=1)\n",
    "TREFMNAV = np.append(TREFMNAV, TREFMNAV_fut, axis=1)\n",
    "TREFMXAV = np.append(TREFMXAV_hist, TREFMXAV_cur, axis=1)\n",
    "TREFMXAV = np.append(TREFMXAV, TREFMXAV_fut, axis=1)\n",
    "lens2_t2m = (TREFMNAV + TREFMXAV) / 2.\n",
    "\n",
    "lens2_t2m_y = np.mean(np.reshape(lens2_t2m, (lens2_t2m.shape[0], int(lens2_t2m.shape[1]/12), 12)), axis=2)\n",
    "\n",
    "ref_t2m = np.mean(lens2_t2m_y[:,(years >= reference_period[0]) & (years <= reference_period[1])])\n",
    "time_to_t2m = np.mean(lens2_t2m_y, axis=0) - ref_t2m\n",
    "\n",
    "dc_hist = np.arange(0,1.5,0.1)\n",
    "dc_pgw = np.arange(0,3.5,0.1)\n",
    "dc = 0.25 # deg. C\n",
    "\n",
    "ref_period = [1950,1979]\n",
    "\n",
    "era5_ref = np.mean(data['No_Smoothing'][(data['Year'] >= ref_period[0]) & (data['Year'] <= ref_period[1])])\n",
    "era5_warming = np.squeeze(np.array([data['No_Smoothing'][data['Year'] == yy] - era5_ref for yy in range(1980,2022,1)]))\n",
    "\n",
    "lens2_ref = np.mean(time_to_t2m[(years >= ref_period[0]) & (years <= ref_period[1])])\n",
    "lens2_warming = np.array([time_to_t2m[years == yy][0] - lens2_ref for yy in range(2022,2022+len(np.unique(time_c404_pgw.year)),1)])\n",
    "\n",
    "pgw_warming = np.zeros((len(years_ctr))); pgw_warming[:] = np.nan\n",
    "for yy in range(len(years_ctr)):\n",
    "    lens_hist = (years <= years_ctr[yy] + 5) & (years >= years_ctr[yy] - 5)\n",
    "    lens_fut = (years <= years_ctr[yy] + 40 + 5) & (years >= years_ctr[yy] + 40 - 5)\n",
    "    pgw_warming[yy] = data['No_Smoothing'][years_ctr[yy] == data['Year']] + np.mean(time_to_t2m[lens_fut]) - np.mean(time_to_t2m[lens_hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8257b37d-8735-40b2-bf78-9940060565fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "warming_tar = 0.25\n",
    "targ_ref = years_ctr[(era5_warming >= warming_tar - dc) & (era5_warming <= warming_tar + dc)]\n",
    "\n",
    "warming_tar = 1\n",
    "targ_1C = years_ctr[(era5_warming >= warming_tar - dc) & (era5_warming <= warming_tar + dc)]\n",
    "\n",
    "warming_tar = 2\n",
    "targ_2C = years_pgw[(pgw_warming[:len(years_pgw)] >= warming_tar - dc) & (pgw_warming[:len(years_pgw)] <= warming_tar + dc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9486f-dd2e-444b-ba7d-a70a398b38d2",
   "metadata": {},
   "source": [
    "# Read CONUS404 CTR OR PGW WBGT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f40e68a-f715-4fa0-bb24-d7cc5e1663e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CONUS404 coordinates\n",
    "ncid=Dataset('/glade/campaign/ncar/USGS_Water/CONUS404/wrfconstants_d01_1979-10-01_00:00:00.nc4', mode='r')\n",
    "lon_conus = np.array(np.squeeze(ncid.variables['XLONG'][:]))\n",
    "lat_conus = np.array(np.squeeze(ncid.variables['XLAT'][:]))\n",
    "ncid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84ad227f-bc1d-46f1-bed7-294a3d4d1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrf import (to_np, getvar, smooth2d, get_cartopy, cartopy_xlim,\n",
    "                 cartopy_ylim, latlon_coords)\n",
    "import cartopy.feature as cf\n",
    "import cartopy.crs as ccrs\n",
    "GEO_EM_D1 = '/glade/u/home/prein/projects/2020/2020_CONUS404/programs/plots/Domain/geo_em.d01.nc'\n",
    "ncfile = Dataset(GEO_EM_D1)\n",
    "HGT_M = getvar(ncfile, \"HGT_M\")\n",
    "LU = getvar(ncfile, \"LU_INDEX\")\n",
    "cart_proj = get_cartopy(HGT_M)\n",
    "ncid.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea757d4f-1727-472b-b05f-6bcad515ab6d",
   "metadata": {},
   "source": [
    "### Process heat extreme data for cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1751a14e-33c2-45b2-a4c7-e48f31d1e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Heatwave length and frequency\n",
    "def heatwave_stat(data):\n",
    "\n",
    "    label_im, nb_labels = ndimage.label(data >= 305.372)\n",
    "    hw_feq = np.sum(np.unique(label_im, return_counts=True)[1][1:] >= 3) # !!! events longer or equal 3 days\n",
    "    objects = scipy.ndimage.find_objects(label_im, axis=0)\n",
    "    max_len = np.max([objects[ii][0].stop - objects[ii][0].start for ii in range(len(objects))])\n",
    "    av_freq = hw_feq\n",
    "    \n",
    "    return max_len, av_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d74d606a-6a85-422c-86ab-edb4c83a798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work on /glade/campaign/mmm/c3we/prein/Papers/2024/2024_WBGT-climate-change/heatwaves//pgw_2021_heatwave-stats_v1.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "  8%|▊         | 1/12 [00:10<01:53, 10.36s/it]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:14<01:04,  6.41s/it]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:20<00:56,  6.31s/it]\u001b[A\n",
      " 33%|███▎      | 4/12 [00:25<00:47,  5.98s/it]\u001b[A\n",
      " 42%|████▏     | 5/12 [00:31<00:41,  5.94s/it]\u001b[A\n",
      " 50%|█████     | 6/12 [00:36<00:33,  5.57s/it]\u001b[A\n",
      " 58%|█████▊    | 7/12 [00:40<00:26,  5.24s/it]\u001b[A\n",
      " 67%|██████▋   | 8/12 [00:46<00:20,  5.23s/it]\u001b[A\n",
      " 75%|███████▌  | 9/12 [00:52<00:17,  5.87s/it]\u001b[A\n",
      " 98%|█████████▊| 41/42 [00:53<00:01,  1.31s/it]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/glade/campaign/mmm/c3we/prein/CONUS404/data/MonthlyData_PGW/GWBT/GWBT_202110_CONUS404.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/glade/campaign/mmm/c3we/prein/CONUS404/data/MonthlyData_PGW/GWBT/GWBT_202110_CONUS404.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '3677dda5-f30b-4d07-b639-f5073649068e']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# # Load data\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mm \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m12\u001b[39m)):\n\u001b[0;32m---> 23\u001b[0m     data_ctr \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir_act\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/GWBT_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myears\u001b[49m\u001b[43m[\u001b[49m\u001b[43myy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmm\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzfill\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_CONUS404.nc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m simulation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mctr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     25\u001b[0m         wbgt_act \u001b[38;5;241m=\u001b[39m data_ctr\u001b[38;5;241m.\u001b[39mGWBT\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/api.py:670\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    659\u001b[0m     decode_cf,\n\u001b[1;32m    660\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    666\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    667\u001b[0m )\n\u001b[1;32m    669\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 670\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    677\u001b[0m     backend_ds,\n\u001b[1;32m    678\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    689\u001b[0m )\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:666\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, auto_complex, lock, autoclose)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    646\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m ReadBuffer \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    663\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    664\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m    665\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 666\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mNetCDF4DataStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    679\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:452\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, auto_complex, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    448\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_complex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m auto_complex\n\u001b[1;32m    449\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    450\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    451\u001b[0m )\n\u001b[0;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:393\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:461\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:455\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m    456\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/glade/u/apps/opt/conda/envs/npl-2023b/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2464\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2027\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/glade/campaign/mmm/c3we/prein/CONUS404/data/MonthlyData_PGW/GWBT/GWBT_202110_CONUS404.nc'"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import label\n",
    "\n",
    "lat_size = lon_conus.shape[0]\n",
    "lon_size = lon_conus.shape[1]\n",
    "\n",
    "if simulation == \"ctr\":\n",
    "    time = time_c404_ctr\n",
    "    data_dir_act = data_dir\n",
    "else:\n",
    "    time = time_c404_pgw\n",
    "    data_dir_act = conus404_pgw_dir\n",
    "\n",
    "years = np.unique(time.year)\n",
    "for yy in tqdm(range(len(years))):\n",
    "    save_file = save_dir_base + \"/\" + simulation + \"_\" + str(years[yy]) + \"_heatwave-stats_v1.nc\"\n",
    "    if os.path.exists(save_file) == False:\n",
    "        print(\"work on \"+save_file)\n",
    "        time_year = time[time.year == years[yy]]\n",
    "        time_year_day = time_year[::24]\n",
    "        data_year = np.zeros((int(len(time_year)/24), lon_conus.shape[0], lon_conus.shape[1])); data_year[:] = np.nan\n",
    "        # # Load data\n",
    "        for mm in tqdm(range(12)):\n",
    "            data_ctr = xr.open_dataset(data_dir_act+\"/GWBT_\"+str(years[yy])+str(int(mm+1)).zfill(2)+\"_CONUS404.nc\")\n",
    "            if simulation == \"ctr\":\n",
    "                wbgt_act = data_ctr.GWBT.values\n",
    "            else:\n",
    "                wbgt_act = data_ctr.__xarray_dataarray_variable__.values\n",
    "            wbgt_act = np.max(np.reshape(wbgt_act, (int(wbgt_act.shape[0]/24),24, lon_conus.shape[0], lon_conus.shape[1])), axis=1)\n",
    "            data_year[time_year_day.month == int(mm+1),:,:] = wbgt_act\n",
    "\n",
    "\n",
    "    \n",
    "        # Initialize output arrays\n",
    "        frequency = np.zeros((lat_size, lon_size), dtype=int)\n",
    "        longest_period = np.zeros((lat_size, lon_size), dtype=int)\n",
    "    \n",
    "        exceed_mask = data_year > 305.372\n",
    "        # Loop over each grid cell (lat, lon)\n",
    "        for lat in range(lat_size):\n",
    "            for lon in range(lon_size):\n",
    "                # Get the time series for this grid point\n",
    "                time_series = exceed_mask[:, lat, lon]\n",
    "\n",
    "                label_im, nb_labels = ndimage.label(time_series)\n",
    "                frequency[lat, lon] = np.sum(np.unique(label_im, return_counts=True)[1][1:] >= 3) # !!! events longer or equal 3 days\n",
    "                objects = scipy.ndimage.find_objects(label_im)\n",
    "                try:\n",
    "                    longest_period[lat, lon] = np.max([objects[ii][0].stop - objects[ii][0].start for ii in range(len(objects))])\n",
    "                except:\n",
    "                    continue\n",
    "        ds = xr.Dataset(\n",
    "                {\n",
    "                    \"frequency\": ([\"lat\", \"lon\"], frequency),\n",
    "                    \"longest_period\": ([\"lat\", \"lon\"], longest_period),\n",
    "                },\n",
    "                coords={\n",
    "                    # \"lat\": np.linspace(25, 50, lat_size),     # 1D latitudes\n",
    "                    # \"lon\": np.linspace(-130, -60, lon_size),  # 1D longitudes\n",
    "                    \"lat_2d\": ([\"lat\", \"lon\"], lat_conus),  # 2D latitude grid\n",
    "                    \"lon_2d\": ([\"lat\", \"lon\"], lon_conus),  # 2D longitude grid\n",
    "                },\n",
    "            )\n",
    "\n",
    "        # Save to a NetCDF file\n",
    "        ds.to_netcdf(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1257a20-9c20-4d8c-a00e-13de7179743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_act+\"/GWBT_\"+str(years[yy])+str(int(mm+1)).zfill(2)+\"_CONUS404.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce7695-7da5-41ff-aca6-59e1eda2897b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ea556-c5ea-4894-b6a5-ef5e75d4ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8cce0-1ff7-46e1-99fd-3888e7af9e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4beba8d-15e4-4428-8ef1-e3679d280b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c4bc9-27af-4a1b-8ef5-b1f63988828c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e231e4f-8326-4cda-afe1-0ef174f7ce01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0c6db-f4c2-4d1e-b4fc-9357493f4d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf66cf6-0827-417e-af81-217f0938f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#33a02c','#ff7f00','#e31a1c']\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "gs1 = gridspec.GridSpec(1,1) #rgiSize[2])\n",
    "gs1.update(left=0.1, right=0.95,\n",
    "           bottom=0.1, top=0.95,\n",
    "           wspace=0.75, hspace=0.60)\n",
    "ax = plt.subplot(gs1[0,0])\n",
    "for cy in range(len(cities_sel)):\n",
    "    for wl in range(3):\n",
    "        ax.scatter(np.nanpercentile(city_hw_length[cy,:,wl], (50), axis=0), \n",
    "                np.nanpercentile(city_hw_freq[cy,:,wl], (50), axis=0), \n",
    "                s=0)\n",
    "        ax.text(np.nanpercentile(city_hw_length[cy,:,wl], (50), axis=0), \n",
    "                np.nanpercentile(city_hw_freq[cy,:,wl], (50), axis=0), \n",
    "                city_acronyms[cy],\n",
    "                #fontsize=12,\n",
    "                color=colors[wl], label=cities_sel[cy],\n",
    "                ha='center', va='center')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67314de-f586-48cf-bdcb-647050e3e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6','#6a3d9a','#DA70D6','#b15928']\n",
    "makersym = ['o','^','s']\n",
    "markername = ['0.25 $^{\\circ}$C','1 $^{\\circ}$C','2 $^{\\circ}$C']\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "ci_sel = np.array([0,0,0,0,1,1,1,0,1,1,1,0])\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "gs1 = gridspec.GridSpec(1,1) #rgiSize[2])\n",
    "gs1.update(left=0.1, right=0.95,\n",
    "           bottom=0.1, top=0.95,\n",
    "           wspace=0.75, hspace=0.60)\n",
    "ax = plt.subplot(gs1[0,0])\n",
    "\n",
    "plt.scatter(city_hw_length[:,:,:].flatten(),\n",
    "           city_hw_freq[:,:,:].flatten(),\n",
    "           s=2, color=\"k\", alpha=0.25)\n",
    "\n",
    "# plot linear regression\n",
    "sns.regplot(x=np.nanmean(city_hw_length[ci_sel == 1,:,:], axis=1).flatten(), \n",
    "            y=np.nanmean(city_hw_freq[ci_sel == 1,:,:], axis=1).flatten(), \n",
    "            ax=ax, scatter=False, ci=95, color=\"black\", line_kws={'label':\"Linear Fit (95% CI)\"},\n",
    "            scatter_kws={'zorder': 0})\n",
    "dN, kN = np.polyfit(np.nanmean(city_hw_length[ci_sel == 1,:,:], axis=1).flatten(), \n",
    "                    np.nanmean(city_hw_freq[ci_sel == 1,:,:], axis=1).flatten(), 1)\n",
    "sns.regplot(x=np.nanmean(city_hw_length[ci_sel == 0,:,:], axis=1).flatten(), \n",
    "            y=np.nanmean(city_hw_freq[ci_sel == 0,:,:], axis=1).flatten(), \n",
    "            ax=ax, scatter=False, ci=95, color=\"black\", line_kws={'linewidth': 1, 'linestyle': 'dashed', 'zorder': 1},\n",
    "            scatter_kws={'zorder': 0})\n",
    "dS, kS = np.polyfit(np.nanmean(city_hw_length[ci_sel == 0,:,:], axis=1).flatten(), \n",
    "                    np.nanmean(city_hw_freq[ci_sel == 0,:,:], axis=1).flatten(), 1)\n",
    "\n",
    "for cy in range(len(cities_sel)):\n",
    "    for wl in range(3):\n",
    "        ax.scatter(np.nanmean(city_hw_length[cy,:,wl], axis=0), \n",
    "                np.nanmean(city_hw_freq[cy,:,wl], axis=0), \n",
    "                s=50,\n",
    "                color=colors[cy],\n",
    "                marker=makersym[wl],\n",
    "                zorder=4)\n",
    "\n",
    "    # connect the different warming levels with colored lins\n",
    "    plt.plot(np.nanmean(city_hw_length[cy,:,:], axis=0), \n",
    "             np.nanmean(city_hw_freq[cy,:,:], axis=0),\n",
    "             color = colors[cy],\n",
    "             lw=1,\n",
    "             zorder=4)\n",
    "\n",
    "    if ci_sel[cy] == 0:\n",
    "        plt.scatter([],[], \n",
    "                 color = colors[cy],\n",
    "                 label= cities[cy],\n",
    "                 marker=\"x\", s=100)\n",
    "    else:\n",
    "        plt.scatter([],[], \n",
    "                 color = colors[cy],\n",
    "                 label= cities[cy],\n",
    "                 marker=\"+\", s=170)\n",
    "\n",
    "for wl in range(3):\n",
    "    plt.scatter([],[], \n",
    "             color = \"k\",\n",
    "             label= markername[wl],\n",
    "             marker=makersym[wl])\n",
    "\n",
    "\n",
    "\n",
    "#plt.legend(ncol=2, fontsize=12)\n",
    "\n",
    "legend = plt.legend(\n",
    "    fontsize=13,       \n",
    "    loc=\"lower right\", \n",
    "    ncol=2,            \n",
    "    frameon=False,      # Remove legend box\n",
    "    handletextpad=0.2,  # Reduce space between marker and text\n",
    "    borderpad=0.1,      # Reduce padding inside legend box\n",
    "    columnspacing=0.3,  # Reduce space between columns\n",
    "    handlelength=1.2,   # Reduce marker line length\n",
    "    labelspacing=0.2,   # Reduce space between rows\n",
    ")\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('mean annual heatwave frequency [days]')\n",
    "plt.xlabel('max annual heatwave duration [days]')\n",
    "plt.xlim(0, 40)\n",
    "plt.ylim(0, 14)\n",
    "ax.set_title('a) Changes in Heatwave Frequency\\nand Maximum Duration Across U.S. Cities')\n",
    "\n",
    "\n",
    "# === Inset Map (CONUS with City Markers) ===\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "ax_inset = plt.axes(projection=ccrs.LambertConformal())\n",
    "ax_inset.set_position([0.55, 0.60, 0.4, 0.4])\n",
    "# Set up Cartopy projection for inset\n",
    "ax_inset.set_extent([-125, -65, 23, 50], crs=ccrs.PlateCarree())  # Focus on CONUS\n",
    "\n",
    "# Add U.S. outline\n",
    "ax_inset.add_feature(cfeature.STATES, \n",
    "                     edgecolor='#969696', \n",
    "                     facecolor='white',     # Fill states with white\n",
    "                     linewidth=0.5, \n",
    "                     zorder=3)\n",
    "\n",
    "# Plot city markers\n",
    "ii = 0\n",
    "for (city, (lat, lon)), selected in zip(city_locations.items(), ci_sel):\n",
    "    if selected == 0:  # Filtering based on ci_sel\n",
    "        ax_inset.scatter(lon, lat, color=colors[ii], \n",
    "                         s=100, marker='x', edgecolor=colors[ii], zorder=4,\n",
    "                         transform=ccrs.PlateCarree())\n",
    "    if selected == 1:  # Filtering based on ci_sel\n",
    "        ax_inset.scatter(lon, lat, color=colors[ii], \n",
    "                         s=170, marker=\"+\", edgecolor=colors[ii], zorder=4,\n",
    "                         transform=ccrs.PlateCarree())\n",
    "    ii += 1  # Increment index only for selected items\n",
    "    \n",
    "# Remove gridlines\n",
    "ax_inset.axis(\"off\")\n",
    "ax_inset.set_xticks([])\n",
    "ax_inset.set_yticks([])\n",
    "\n",
    "sPlotFile=\"\"\n",
    "sPlotName= 'annual-max-WBGT_change.pdf'\n",
    "if os.path.isdir(sPlotFile) != 1:\n",
    "    subprocess.call([\"mkdir\",\"-p\",sPlotFile])\n",
    "print( '        Plot map to: '+sPlotFile+sPlotName)\n",
    "fig.savefig(sPlotFile+sPlotName, bbox_inches='tight') #, dpi=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7310ca8c-f0a9-47ca-b78b-0e8abf693ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dN, kN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a83430-073f-4d13-b9c8-981861c03e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dS, kS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a76595-f4dc-4f30-89d4-8ff7c682306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18529975-0597-4b30-bed3-42614e62eb63",
   "metadata": {},
   "source": [
    "### Read in houlry WBGT over city regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f4ef2-e9ba-4db6-8cfe-0147adab1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cities_sel = ['Phoenix',\n",
    "          'Miami',\n",
    "          # 'Atlanta',\n",
    "          'New York City',\n",
    "            ]\n",
    "\n",
    "urb_cat = [\"urban\",\"rural\"]\n",
    "\n",
    "import string\n",
    "abc_array = list(string.ascii_lowercase) + list(string.ascii_uppercase)\n",
    "\n",
    "# Create a figure and an axis\n",
    "fig = plt.figure(figsize=(18,3.5*len(cities_sel)))\n",
    "gs1 = gridspec.GridSpec(len(cities_sel),3) #rgiSize[2])\n",
    "gs1.update(left=0.06, right=0.35,\n",
    "           bottom=0.13, top=0.97,\n",
    "           wspace=0.75, hspace=0.60)\n",
    "\n",
    "gs2 = gridspec.GridSpec(len(cities_sel)*2,1) #rgiSize[2])\n",
    "gs2.update(left=0.355, right=0.52, #98,\n",
    "           bottom=0.13, top=0.97,\n",
    "           wspace=0.30, hspace=1)\n",
    "\n",
    "gs3 = gridspec.GridSpec(len(cities_sel),1) #rgiSize[2])\n",
    "gs3.update(left=0.6, right=0.75, #98,\n",
    "           bottom=0.13, top=0.97,\n",
    "           wspace=0.30, hspace=0.60)\n",
    "\n",
    "for cc in tqdm(range(len(cities_sel))):\n",
    "    city = cities_sel[cc]\n",
    "    cy = cities.index(city)\n",
    "    save_dir = save_dir_base + city + '/'\n",
    "    LU_city = LU[city_loc[cy][1][0]:city_loc[cy][1][1],\n",
    "             city_loc[cy][0][0]:city_loc[cy][0][1]]\n",
    "    \n",
    "    # # ================================================\n",
    "    # # Load data\n",
    "    data_ctr = xr.open_dataset(save_dir+\"/CONUS404_ctr_\"+cities[cy]+\"_statistics.nc\")\n",
    "    time_ctr = pd.to_datetime(data_ctr.time.values)\n",
    "    lat = data_ctr.latitude.values\n",
    "    lon = data_ctr.longitude.values\n",
    "    wcrp_ctr = data_ctr.WBGT.values\n",
    "    \n",
    "    # load PGW data\n",
    "    data_pgw = xr.open_dataset(save_dir+\"/CONUS404_pgw_\"+cities[cy]+\"_statistics.nc\")\n",
    "    time_pgw = pd.to_datetime(data_pgw.time.values)\n",
    "    lat = data_pgw.latitude.values\n",
    "    lon = data_pgw.longitude.values\n",
    "    wcrp_pgw = data_pgw.WBGT.values\n",
    "    \n",
    "    # load variable attribution results\n",
    "    change_var_categories = ['T2','Q2','PSFC','UV10', 'LW', 'SW']\n",
    "    change_cat_colors = ['#e31a1c','#1f78b4','#969696','#33a02c','#a6cee3','#fb9a99']\n",
    "    savefile =  '/glade/campaign/mmm/c3we/prein/Papers/2024/2024_WBGT-climate-change/city_changes/' + cities[cy] + '_50gc_statistics_urban-rural_2C.npz'\n",
    "    try:\n",
    "        data_cy = np.load(savefile)\n",
    "    except:\n",
    "        print(\"    !!! file not found \"+savefile)\n",
    "        continue\n",
    "    change_sensitivities = data_cy['change_sensitivities_city']\n",
    "    ctr_original_data = data_cy['ctr_original_data_city']\n",
    "    pgw_original_data= data_cy['pgw_original_data_city']\n",
    "    \n",
    "    \n",
    "    # # ================================================\n",
    "    # # Histogram plots\n",
    "    \n",
    "    ax = plt.subplot(gs1[cc,:2])\n",
    "    # Plot using sns.kdeplot\n",
    "    custom_bin_edges = np.arange(-40,50,0.1)\n",
    "    \n",
    "    # historic climate\n",
    "    time_foc = np.in1d(time_c404_ctr.year, targ_ref)\n",
    "    normalize = len(targ_ref) * np.sum(LU_city.values == 13)\n",
    "    data_act = (wcrp_ctr[time_foc,:][:,LU_city == 13][:,::1] - 273.15).flatten()\n",
    "    bfd_fre_ref = np.sum(data_act > 32.2222)/normalize\n",
    "    ax. hist(\n",
    "        data_act,\n",
    "        bins=custom_bin_edges,\n",
    "        density=True,\n",
    "        zorder=5,\n",
    "        edgecolor=\"k\",\n",
    "        alpha=1,\n",
    "        histtype='step',\n",
    "        label = '0.25 $^{\\circ}$C'\n",
    "    )\n",
    "    \n",
    "    # 1C warming\n",
    "    time_foc = np.in1d(time_c404_ctr.year, targ_1C)\n",
    "    normalize = len(targ_1C) * np.sum(LU_city.values == 13)\n",
    "    data_act = (wcrp_ctr[time_foc,:][:,LU_city == 13][:,::1] - 273.15).flatten()\n",
    "    bfd_fre_1C = np.sum(data_act > 32.2222)/normalize\n",
    "    ax.hist(\n",
    "        data_act,\n",
    "        bins=custom_bin_edges,\n",
    "        density=True,\n",
    "        zorder=5,\n",
    "        edgecolor=\"b\",\n",
    "        alpha=1,\n",
    "        histtype='step',\n",
    "        label = '1 $^{\\circ}$C | '+ str(int(((bfd_fre_1C - bfd_fre_ref)/bfd_fre_ref)*100))+' %'\n",
    "    )\n",
    "    \n",
    "    # 2C climate\n",
    "    time_foc = np.in1d(time_c404_pgw.year, targ_2C)\n",
    "    normalize = len(targ_2C) * np.sum(LU_city.values == 13)\n",
    "    data_act = (wcrp_pgw[time_foc,:][:,LU_city == 13][:,::1] - 273.15).flatten()\n",
    "    bfd_fre_2C = np.sum(data_act > 32.2222)/normalize\n",
    "    ax.hist(\n",
    "        data_act,\n",
    "        bins=custom_bin_edges,\n",
    "        density=True,\n",
    "        zorder=5,\n",
    "        edgecolor=\"r\",\n",
    "        alpha=1,\n",
    "        histtype='step',\n",
    "        label = '2 $^{\\circ}$C | '+ str(int(((bfd_fre_2C - bfd_fre_ref)/bfd_fre_ref)*100))+' %'\n",
    "    )\n",
    "    \n",
    "    ax.set_xlim([25, 44])\n",
    "    ax.set_yscale('log')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.axvline(x=26.6667, c = '#33a02c', ls = ':')\n",
    "    plt.axvline(x=29.4444, c = '#ffed6f', ls = ':')\n",
    "    plt.axvline(x=31.1111, c = '#e31a1c', ls = ':')\n",
    "    plt.axvline(x=32.2222, c = 'k', ls = ':')\n",
    "\n",
    "    plt.legend() \n",
    "    # Customize the plot as needed\n",
    "    ax.set_title(abc_array[cc*5]+') hourly WBGT PDF '+cities[cy])\n",
    "\n",
    "    # Add row title (centered text on the left of the row)\n",
    "    ax.text(-0.2, 0.5, cities_sel[cc], fontsize=15, fontweight=\"bold\",\n",
    "            rotation=90, ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "    \n",
    "    # ================================================\n",
    "    print(\"    Variable attribution\")\n",
    "    ax = plt.subplot(gs1[cc,2])\n",
    "    for cr in [0]: #range(len(urb_cat)):\n",
    "        # city=0, rural=1\n",
    "        mean_change = np.nanmedian(pgw_original_data[:,:,cr]) - np.nanmedian(ctr_original_data[:,:,cr])\n",
    "        \n",
    "        plt.plot([0.1+cr,0.1+cr],[0,mean_change], c='k', lw=1)\n",
    "        plt.plot([0.9+cr,0.9+cr],[0,mean_change], c='k', lw=1)\n",
    "        plt.plot([0.1+cr,0.9+cr],[mean_change,mean_change], c='k', lw=3)\n",
    "        \n",
    "        # Add the components from different variables\n",
    "        orig_change = np.nanmedian(pgw_original_data[:,:,cr]) - np.nanmedian(ctr_original_data[:,:,cr])\n",
    "        mean_change_vars = (np.nanmedian(change_sensitivities[:,:,:,cr], axis=(0,1)) - np.nanmedian(ctr_original_data[:,:,cr]))\n",
    "        change_deltas = orig_change - (np.nanmedian(change_sensitivities[:,:,:,cr], axis=(0,1)) - np.nanmedian(ctr_original_data[:,:,cr]))\n",
    "        \n",
    "        for va in range(change_sensitivities.shape[2]):\n",
    "            if va == 0:\n",
    "                start = 0\n",
    "            else:\n",
    "                start = np.sum(change_deltas[:va])\n",
    "            plt.arrow(0.3+0.1*va+cr, start, 0, np.sum(change_deltas[:va+1])-start, length_includes_head=True,\n",
    "                      head_width=0.1, head_length=0.05,\n",
    "                      color=change_cat_colors[va],\n",
    "                      lw=3)\n",
    "        \n",
    "        plt.xlim(-0.1, 1.1)\n",
    "        plt.ylim(0, 2)\n",
    "        \n",
    "        for va in range(change_sensitivities.shape[2]):\n",
    "            plt.plot([],[], label = change_var_categories[va], lw = 3, color = change_cat_colors[va])\n",
    "    \n",
    "        if (cc == 0) & (cr == 0):\n",
    "            plt.legend(ncol=2)\n",
    "        \n",
    "    ax.set_xticks([0.5])#,1.5])\n",
    "    ax.set_xticklabels([cities_sel[cc]], rotation=0)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.ylabel('annual max. WBGT change [K]')\n",
    "    ax.set_title(abc_array[cc*5+1]+') WBGT change at\\n2$^{\\circ}$C warming')\n",
    "\n",
    "    \n",
    "    # ================================================\n",
    "    # Annual cycle of black flag days\n",
    "    ax = plt.subplot(gs2[cc*2,0], polar=True, zorder=cc)\n",
    "    from math import pi\n",
    "    original_position = ax.get_position()  # Returns Bbox object    \n",
    "    # Expand the axis position (left, bottom, width, height)\n",
    "    new_position = [\n",
    "        original_position.x0 ,  # Shift left a bit\n",
    "        original_position.y0 -0.05 ,  # Shift down a bit\n",
    "        original_position.width * 2,  # Increase width\n",
    "        original_position.height * 2,  # Increase height\n",
    "    ]\n",
    "    ax.set_position(new_position)\n",
    "    \n",
    "    # number of variable\n",
    "    categories=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    N = 12\n",
    "     \n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "     \n",
    "    # If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "     \n",
    "    # Draw one axe per variable + add labels\n",
    "    plt.xticks(angles[:-1], categories)\n",
    "     \n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    # plt.yticks([10,20,30], [\"10\",\"20\",\"30\"], color=\"grey\", size=7)\n",
    "    # plt.ylim(0,40)\n",
    "    \n",
    "    # 0.25 C\n",
    "    seasonal_cycle = np.zeros((12)); seasonal_cycle[:] = np.nan\n",
    "    normalize = len(targ_ref) * np.sum(LU_city.values == 13)\n",
    "    for mm in range(12):\n",
    "        time_foc = (np.in1d(time_c404_ctr.year, targ_ref)) & (time_c404_ctr.month == mm+1)\n",
    "        seasonal_cycle[mm] = np.sum((wcrp_ctr[time_foc,:][:,LU_city == 13]).flatten() > 305.372) / normalize\n",
    "    values=seasonal_cycle.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, linewidth=2, linestyle='solid', label=\"0.25 C\", color='k')\n",
    "    # ax.fill(angles, values, 'b', alpha=0.1)\n",
    "    \n",
    "    # 1 C\n",
    "    seasonal_cycle = np.zeros((12)); seasonal_cycle[:] = np.nan\n",
    "    normalize = len(targ_1C) * np.sum(LU_city.values == 13)\n",
    "    for mm in range(12):\n",
    "        time_foc = (np.in1d(time_c404_ctr.year, targ_1C)) & (time_c404_ctr.month == mm+1)\n",
    "        seasonal_cycle[mm] = np.sum((wcrp_ctr[time_foc,:][:,LU_city == 13]).flatten() > 305.372) / normalize\n",
    "    values=seasonal_cycle.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, linewidth=2, linestyle='solid', label=\"1 C\", color='b')\n",
    "    \n",
    "    # 2 C\n",
    "    seasonal_cycle = np.zeros((12)); seasonal_cycle[:] = np.nan\n",
    "    normalize = len(targ_2C) * np.sum(LU_city.values == 13)\n",
    "    for mm in range(12):\n",
    "        time_foc = (np.in1d(time_c404_pgw.year, targ_2C)) & (time_c404_pgw.month == mm+1)\n",
    "        seasonal_cycle[mm] = np.sum((wcrp_pgw[time_foc,:][:,LU_city == 13]).flatten() > 305.372) / normalize\n",
    "    values=seasonal_cycle.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, linewidth=2, linestyle='solid', label=\"2 C\", color='r')\n",
    "\n",
    "    ax.set_thetamin(90)\n",
    "    ax.set_thetamax(270)\n",
    "    ax.tick_params(axis='y', rotation=45)\n",
    "    ax.set_title(abc_array[cc*5+2]+') Seasonal cycle of BF day frequency', pad=-10)\n",
    "    \n",
    "    # ================================================\n",
    "    # Diurnal cycle of black flag days\n",
    "    ax = plt.subplot(gs2[cc*2+1,0], polar=True, zorder=cc)\n",
    "    from math import pi\n",
    "    original_position = ax.get_position()  # Returns Bbox object    \n",
    "    # Expand the axis position (left, bottom, width, height)\n",
    "    new_position = [\n",
    "        original_position.x0 ,  # Shift left a bit\n",
    "        original_position.y0 -0.05, #-0.2 ,  # Shift down a bit\n",
    "        original_position.width * 2,  # Increase width\n",
    "        original_position.height * 2,  # Increase height\n",
    "    ]\n",
    "    ax.set_position(new_position)\n",
    "    \n",
    "    # number of variable\n",
    "    utc_diff = int(np.round(solar_time_difference_from_utc(np.mean(lon)).total_seconds() / 3600, 0))\n",
    "    categories= np.array(range(24))\n",
    "    N = 24\n",
    "     \n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "     \n",
    "    # If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "     \n",
    "    # Draw one axe per variable + add labels\n",
    "    plt.xticks(angles[:-1], categories)\n",
    "     \n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    # plt.yticks([10,20,30], [\"10\",\"20\",\"30\"], color=\"grey\", size=7)\n",
    "    # plt.ylim(0,40)\n",
    "    \n",
    "    # 0.25 C\n",
    "    diurnal_cycle = np.zeros((24)); seasonal_cycle[:] = np.nan\n",
    "    normalize = len(targ_ref) * np.sum(LU_city.values == 13)\n",
    "    for hh in range(24):\n",
    "        time_foc = (np.in1d(time_c404_ctr.year, targ_ref)) & (time_c404_ctr.hour == hh+1)\n",
    "        diurnal_cycle[hh] = np.sum((wcrp_ctr[time_foc,:][:,LU_city == 13]).flatten() > 305.372) / normalize\n",
    "    diurnal_cycle =  np.roll(diurnal_cycle, utc_diff)\n",
    "    values=diurnal_cycle.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, linewidth=2, linestyle='solid', label=\"0.25 C\", color='k')\n",
    "    # ax.fill(angles, values, 'b', alpha=0.1)\n",
    "    \n",
    "    # 1 C\n",
    "    diurnal_cycle = np.zeros((24)); seasonal_cycle[:] = np.nan\n",
    "    normalize = len(targ_1C) * np.sum(LU_city.values == 13)\n",
    "    for hh in range(24):\n",
    "        time_foc = (np.in1d(time_c404_ctr.year, targ_1C)) & (time_c404_ctr.hour == hh+1)\n",
    "        diurnal_cycle[hh] = np.sum((wcrp_ctr[time_foc,:][:,LU_city == 13]).flatten() >= 305.372) / normalize\n",
    "    diurnal_cycle =  np.roll(diurnal_cycle, utc_diff)\n",
    "    values=diurnal_cycle.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, linewidth=2, linestyle='solid', label=\"1 C\", color='b')\n",
    "    \n",
    "    \n",
    "    # 2 C\n",
    "    diurnal_cycle = np.zeros((24)); seasonal_cycle[:] = np.nan\n",
    "    normalize = len(targ_2C) * np.sum(LU_city.values == 13)\n",
    "    for hh in range(24):\n",
    "        time_foc = (np.in1d(time_c404_pgw.year, targ_2C)) & (time_c404_pgw.hour == hh+1)\n",
    "        diurnal_cycle[hh] = np.sum((wcrp_pgw[time_foc,:][:,LU_city == 13]).flatten() > 305.372) / normalize\n",
    "    diurnal_cycle =  np.roll(diurnal_cycle, utc_diff)\n",
    "    values=diurnal_cycle.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, linewidth=2, linestyle='solid', label=\"2 C\", color='r')\n",
    "\n",
    "    ax.set_thetamin(90)\n",
    "    ax.set_thetamax(270)\n",
    "    ax.tick_params(axis='y', rotation=45)\n",
    "    \n",
    "    if cc == 0:\n",
    "        plt.legend() #loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    ax.set_title(abc_array[cc*5+3]+') Diurnal cycle of BF hour frequency', pad=-10)\n",
    "    \n",
    "    # ================================================\n",
    "    # Heatwave length and frequency\n",
    "    ax = plt.subplot(gs3[cc,0])\n",
    "    sns.set_style(\"white\")\n",
    "    \n",
    "    def heatwave_stat(data,\n",
    "                      time_hh,\n",
    "                     targ_ref,\n",
    "                     LU_city):\n",
    "        max_len = np.zeros(len(targ_ref))\n",
    "        av_freq = np.zeros(len(targ_ref))\n",
    "        for yy in range(len(targ_ref)):\n",
    "            time_foc = (np.in1d(time_hh.year, targ_ref[yy]))\n",
    "            data_year = np.max(data[time_foc,:][:,LU_city == 13], axis = 1)\n",
    "            data_year = np.max(np.reshape(data_year, (int(data_year.shape[0]/24), 24)), axis = 1)\n",
    "            label_im, nb_labels = ndimage.label(data_year >= 305.372)\n",
    "            objects = scipy.ndimage.find_objects(label_im)\n",
    "            try:\n",
    "                max_len[yy] = np.max([objects[ii][0].stop - objects[ii][0].start for ii in range(len(objects))])\n",
    "            except:\n",
    "                continue\n",
    "            av_freq[yy] = nb_labels-1\n",
    "        return max_len, av_freq\n",
    "    \n",
    "    # 0.25 C\n",
    "    max_len, av_freq = heatwave_stat(wcrp_ctr, time_c404_ctr, targ_ref, LU_city)\n",
    "    # ax.plot(np.percentile(max_len, (0,100)), [np.median(av_freq), np.median(av_freq)], c = 'k')\n",
    "    sns.kdeplot(x=max_len, y=av_freq, cmap=\"Greys\", fill=True, alpha=0.5, lw=0)\n",
    "    plt.errorbar(np.median(max_len), np.median(av_freq), \n",
    "                 xerr=[[np.median(max_len)-np.percentile(max_len, (10))],[np.percentile(max_len, (90))-np.median(max_len)]], \n",
    "                 yerr=[[np.median(av_freq)-np.percentile(av_freq, (10))],[np.percentile(av_freq, (90))-np.median(av_freq)]], \n",
    "                 fmt='o', c='k', capsize=5, capthick=1)\n",
    "    \n",
    "    # 1 C\n",
    "    max_len, av_freq = heatwave_stat(wcrp_ctr, time_c404_ctr, targ_1C, LU_city)\n",
    "    # ax.plot(np.percentile(max_len, (0,100)), [np.median(av_freq), np.median(av_freq)], c = 'k')\n",
    "    # sns.kdeplot(x=max_len, y=av_freq, cmap=\"Blues\", fill=True, alpha=0.5)\n",
    "    plt.errorbar(np.median(max_len), np.median(av_freq), \n",
    "                 xerr=[[np.median(max_len)-np.percentile(max_len, (10))],[np.percentile(max_len, (90))-np.median(max_len)]], \n",
    "                 yerr=[[np.median(av_freq)-np.percentile(av_freq, (10))],[np.percentile(av_freq, (90))-np.median(av_freq)]], \n",
    "                 fmt='o', c='b', capsize=5, capthick=1)\n",
    "    \n",
    "    # 2 C\n",
    "    max_len, av_freq = heatwave_stat(wcrp_pgw, time_c404_pgw, targ_2C, LU_city)\n",
    "    # ax.plot(np.percentile(max_len, (0,100)), [np.median(av_freq), np.median(av_freq)], c = 'k')\n",
    "    sns.kdeplot(x=max_len, y=av_freq, cmap=\"Reds\", fill=False, alpha=0.5)\n",
    "    plt.errorbar(np.median(max_len), np.median(av_freq), \n",
    "                 xerr=[[np.median(max_len)-np.percentile(max_len, (10))],[np.percentile(max_len, (90))-np.median(max_len)]], \n",
    "                 yerr=[[np.median(av_freq)-np.percentile(av_freq, (10))],[np.percentile(av_freq, (90))-np.median(av_freq)]], \n",
    "                 fmt='o', c='r', capsize=5, capthick=1)\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.xlim(0, 60)\n",
    "    plt.ylim(0, 45)\n",
    "    \n",
    "    plt.xlabel('annual max. heatwave length [days]')\n",
    "    plt.ylabel('number of heatwaves per year')\n",
    "    ax.set_title(abc_array[cc*5+4]+') Heatwave length and frequency')\n",
    "\n",
    "sPlotFile=\"\"\n",
    "sPlotName= 'city_heatwaves.pdf'\n",
    "if os.path.isdir(sPlotFile) != 1:\n",
    "    subprocess.call([\"mkdir\",\"-p\",sPlotFile])\n",
    "print( '        Plot map to: '+sPlotFile+sPlotName)\n",
    "fig.savefig(sPlotFile+sPlotName) #, dpi=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b1dc88-2abe-4112-945d-cf2a560f7686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe22960-ac48-400f-aa8d-586ff834ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "sns.kdeplot(x=max_len, y=av_freq, cmap=\"Reds\", fill=False, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a936a-860b-4687-8b56-c3e5ef60f343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cab87f-9501-469d-9afd-6abfbad32da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6ad55-93ef-4b6d-af1c-1cc8bcc0b51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb57327-c87b-4941-b438-ea9ba00c8712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9074f0e-d1f7-4344-9988-a731c40646e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e94ad-c768-44a1-ae68-63288ff99301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5598138c-6a00-4d24-9bc9-698598f18c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768355df-7d38-47bf-852b-5f5b541730bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30879b-4dd9-48f3-a997-a681268d0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgw_data = np.zeros((len(years_pgw),12,lon_conus.shape[0],lon_conus.shape[1])); pgw_data[:] = np.nan\n",
    "pgw_time = np.empty((len(years_pgw),12,lon_conus.shape[0],lon_conus.shape[1]), dtype='datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa735e-4110-49b7-bac6-14260945ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for yy in tqdm(range(len(years_pgw))):\n",
    "    for mm in range(12):\n",
    "        datafile = data_dir + str(years_pgw[yy]) + str(mm+1).zfill(2) +'_WBGT_monmax_variables_pgw.npz'\n",
    "        if os.path.isfile(datafile) == True:\n",
    "            data = np.load(datafile)\n",
    "            pgw_data[yy,mm,:,:] = data['conus_ctr'][:,:,0]\n",
    "            pgw_time[yy,mm,:] = data['timestamp_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450865bd-7d8c-48bb-83b2-7e07997f2aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_max = np.nanargmax(ctr_data[:,:,:,:], axis=1)\n",
    "y,la,lo = np.indices(ctr_data[:,0,:,:].shape)\n",
    "\n",
    "ymax_ctr = np.copy(ctr_data[:,0,:,:]); ymax_ctr[:]=np.nan\n",
    "ymax_ctr[:,:,:] = ctr_data[y, month_max, la, lo]\n",
    "ytime_ctr = ctr_time[y, month_max, la, lo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157503dc-3e3e-42c9-bda6-6654f2b9e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_max = np.nanargmax(pgw_data[:,:,:,:], axis=1)\n",
    "y,la,lo = np.indices(pgw_data[:,0,:,:].shape)\n",
    "\n",
    "ymax_pgw = np.copy(pgw_data[:,0,:,:]); ymax_pgw[:]=np.nan\n",
    "ymax_pgw[:,:,:] = pgw_data[y, month_max, la, lo]\n",
    "ytime_pgw = pgw_time[y, month_max, la, lo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998287a2-2002-4292-af79-e491cab91d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.nanmean(np.nanmax(pgw_data[:,:,:,:], axis=(1)), axis=(1,2))-273.15, c='r')\n",
    "plt.plot(np.nanmean(np.nanmax(ctr_data[:,:,:,:], axis=(1)), axis=(1,2))-273.15, c='b')\n",
    "\n",
    "plt.show()\n",
    "# plt.plot(c_pgw_years, np.nanmean(conus_pgw_wbgt, axis=(1,2))-273.15, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b715570b-e0f9-4315-ac13-8cbc2369e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fut = np.nanmean(np.nanmax(pgw_data[:,:,:,:], axis=(1)), axis=(1,2))-273.15\n",
    "cur = np.nanmean(np.nanmax(ctr_data[:,:,:,:], axis=(1)), axis=(1,2))-273.15\n",
    "plt.plot(fut - cur[:len(fut)], c='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd8cc1-a610-4c20-9a5c-d119467ead74",
   "metadata": {},
   "source": [
    "### Load hourly data over city and derive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd504c-efe8-47c5-a09b-095a0d1130cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['CONUS404_ctr', 'CONUS404_pgw']\n",
    "flag_thresholds = [29, 31, 32]\n",
    "\n",
    "lat_cy = lat_conus[city_loc[cy][1][0]:city_loc[cy][1][1],\n",
    "                   city_loc[cy][0][0]:city_loc[cy][0][1]]\n",
    "lon_cy = lon_conus[city_loc[cy][1][0]:city_loc[cy][1][1],\n",
    "                   city_loc[cy][0][0]:city_loc[cy][0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3860fbbd-5d00-43cd-b123-1144a54f51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for da in [1]: #range(len(datasets)):\n",
    "    print('WORK ON '+datasets[da])\n",
    "    outfile = save_dir + datasets[da] + '_'+city+'_statistics.nc'\n",
    "    if os.path.isfile(outfile) == False:\n",
    "        if datasets[da] == 'CONUS404_ctr':\n",
    "            data_dir = '/glade/campaign/mmm/c3we/prein/CONUS404/data/MonthlyData/GWBT/'\n",
    "            time = pd.date_range(datetime.datetime(1980, 1, 1, 0), \n",
    "                                  end=datetime.datetime(2022, 12, 31, 23), freq='h')\n",
    "            data_cy = np.zeros((len(time), lat_cy.shape[0], lat_cy.shape[1]))\n",
    "            years = np.unique(time.year)\n",
    "            for yy in tqdm(range(len(years))):\n",
    "                for mm in range(12):\n",
    "                    time_act = (years[yy] == time.year) & (mm+1 == time.month)\n",
    "                    file = data_dir + 'GWBT_'+str(years[yy])+str(mm+1).zfill(2)+'_CONUS404.nc'\n",
    "                    ncid=Dataset(file, mode='r')\n",
    "                    data_cy[time_act,:] = np.array(np.squeeze(ncid.variables['GWBT'][:,city_loc[cy][1][0]:city_loc[cy][1][1],\n",
    "                                                                             city_loc[cy][0][0]:city_loc[cy][0][1]]))\n",
    "                    ncid.close()\n",
    "    \n",
    "        elif datasets[da] == 'CONUS404_pgw':\n",
    "            data_dir = '/glade/campaign/mmm/c3we/prein/CONUS404/data/MonthlyData_PGW/GWBT/'\n",
    "            time = pd.date_range(datetime.datetime(1980, 1, 1, 0), \n",
    "                                  end=datetime.datetime(2011, 12, 31, 23), freq='h')\n",
    "            data_cy = np.zeros((len(time), lat_cy.shape[0], lat_cy.shape[1]))\n",
    "            years = np.unique(time.year)\n",
    "            for yy in tqdm(range(len(years))):\n",
    "                for mm in range(12):\n",
    "                    time_act = (years[yy] == time.year) & (mm+1 == time.month)\n",
    "                    file = data_dir + 'GWBT_'+str(years[yy])+str(mm+1).zfill(2)+'_CONUS404.nc'\n",
    "                    ncid=Dataset(file, mode='r')\n",
    "                    data_cy[time_act,:] = np.array(np.squeeze(ncid.variables['__xarray_dataarray_variable__'][:,city_loc[cy][1][0]:city_loc[cy][1][1],\n",
    "                                                                             city_loc[cy][0][0]:city_loc[cy][0][1]]))\n",
    "                    ncid.close()\n",
    "    \n",
    "                \n",
    "\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            \"WBGT\": ([\"time\", \"y\", \"x\"], data_cy)\n",
    "        },\n",
    "        coords={\n",
    "            \"time\": time,\n",
    "            \"y\": np.arange(lat_cy.shape[0]),\n",
    "            \"x\": np.arange(lat_cy.shape[1]),\n",
    "            \"latitude\": ([\"y\", \"x\"], lat_cy),\n",
    "            \"longitude\": ([\"y\", \"x\"], lon_cy)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Set attributes (optional but recommended)\n",
    "    ds.attrs['long_name'] = 'Wet bulb globe temperature dimensions time, latitude, longitude'\n",
    "    ds['WBGT'].attrs['units'] = 'K'\n",
    "    \n",
    "    # Write to a NetCDF file\n",
    "    ds.to_netcdf(outfile)\n",
    "    \n",
    "    print(f\"Data successfully written to {outfile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce901c-3b47-442a-a17a-c284f7f3d1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
